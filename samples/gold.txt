{"id": "0806.3537", "abstract": "Statistical learning theory chiefly studies restricted hypothesis classes, particularly those with finite Vapnik-Chervonenkis (VC) dimension. The fundamental quantity of interest is the sample complexity: the number of samples required to learn to a specified level of accuracy. Here we consider learning over the set of all computable labeling functions. Since the VC-dimension is infinite and a priori (uniform) bounds on the number of samples are impossible, we let the learning algorithm decide when it has seen sufficient samples to have learned. We first show that learning in this setting is indeed possible, and develop a learning algorithm. We then show, however, that bounding sample complexity independently of the distribution is impossible. Notably, this impossibility is entirely due to the requirement that the learning algorithm be computable, and not due to the statistical nature of the problem.", "lang": "en", "title": "Statistical Learning of Arbitrary Computable Classifiers", "pdf_url": "http://arxiv.org/pdf/0806.3537v2"}
{"id": "0808.2220", "abstract": "We prove that every computably enumerable (c.e.) random real is provable in Peano Arithmetic (PA) to be c.e. random. A major step in the proof is to show that the theorem stating that \"a real is c.e. and random iff it is the halting probability of a universal prefix-free Turing machine\" can be proven in PA. Our proof, which is simpler than the standard one, can also be used for the original theorem.   Our positive result can be contrasted with the case of computable functions, where not every computable function is provably computable in PA, or even more interestingly, with the fact that almost all random finite strings are not provably random in PA.   We also prove two negative results: a) there exists a universal machine whose universality cannot be proved in PA, b) there exists a universal machine U such that, based on U, PA cannot prove the randomness of its halting probability.   The paper also includes a sharper form of the Kraft-Chaitin Theorem, as well as a formal proof of this theorem written with the proof assistant Isabelle.", "lang": "en", "title": "Every Computably Enumerable Random Real Is Provably Computably\n  Enumerable Random", "pdf_url": "http://arxiv.org/pdf/0808.2220v5"}
{"id": "0811.1250", "abstract": "We develop the concept of ABC-Boost (Adaptive Base Class Boost) for multi-class classification and present ABC-MART, a concrete implementation of ABC-Boost. The original MART (Multiple Additive Regression Trees) algorithm has been very successful in large-scale applications. For binary classification, ABC-MART recovers MART. For multi-class classification, ABC-MART considerably improves MART, as evaluated on several public data sets.", "lang": "en", "title": "Adaptive Base Class Boost for Multi-class Classification", "pdf_url": "http://arxiv.org/pdf/0811.1250v1"}
{"id": "0812.0197", "abstract": "We describe a new methodology for studying persistence of topological features across a family of spaces or point-cloud data sets, called zigzag persistence. Building on classical results about quiver representations, zigzag persistence generalises the highly successful theory of persistent homology and addresses several situations which are not covered by that theory. In this paper we develop theoretical and algorithmic foundations with a view towards applications in topological statistics.", "lang": "en", "title": "Zigzag Persistence", "pdf_url": "http://arxiv.org/pdf/0812.0197v1"}
{"id": "1203.4732", "abstract": "In this extended abstract we provide a unifying framework that can be used to characterize and compare the expressive power of query languages for different data base models. The framework is based upon the new idea of valid partition, that is a partition of the elements of a given data base, where each class of the partition is composed by elements that cannot be separated (distinguished) according to some level of information contained in the data base. We describe two applications of this new framework, first by deriving a new syntactic characterization of the expressive power of relational algebra which is equivalent to the one given by Paredaens, and subsequently by studying the expressive power of a simple graph-based data model.", "lang": "en", "title": "A Unifying Framework to Characterize the Power of a Language to Express\n  Relations", "pdf_url": "http://arxiv.org/pdf/1203.4732v1"}
{"id": "1207.0783", "abstract": "Semi-supervised template update systems allow to automatically take into account the intra-class variability of the biometric data over time. Such systems can be inefficient by including too many impostor's samples or skipping too many genuine's samples. In the first case, the biometric reference drifts from the real biometric data and attracts more often impostors. In the second case, the biometric reference does not evolve quickly enough and also progressively drifts from the real biometric data. We propose a hybrid system using several biometric sub-references in order to increase per- formance of self-update systems by reducing the previously cited errors. The proposition is validated for a keystroke- dynamics authentication system (this modality suffers of high variability over time) on two consequent datasets from the state of the art.", "lang": "en", "title": "Hybrid Template Update System for Unimodal Biometric Systems", "pdf_url": "http://arxiv.org/pdf/1207.0783v1"}
{"id": "1210.1932", "abstract": "Multipersistence homology modules were introduced by G.Carlsson and A.Zomorodian which gave, together with G.Singh, an algorithm to compute their Groebner bases. Although their algorithm has polynomial complexity when the chain modules are free, i.e. in the one-critical case, it might be exponential in general. We give a new presentation of multipersistence homology modules, which allows us to design an algorithm to compute their Groebner bases always in polynomial time by avoiding the mapping telescope.", "lang": "en", "title": "A presentation of general multipersistence modules computable in\n  polynomial time?", "pdf_url": "http://arxiv.org/pdf/1210.1932v2"}
{"id": "1302.4020", "abstract": "The topological interference management problem refers to the study of the capacity of partially connected linear (wired and wireless) communication networks with no channel state information at the transmitters (no CSIT) beyond the network topology, i.e., a knowledge of which channel coefficients are zero (weaker than the noise floor in the wireless case). While the problem is originally studied with fixed topology, in this work we explore the implications of varying connectivity, through a series of simple and conceptually representative examples. Specifically, we highlight the synergistic benefits of coding across alternating topologies.", "lang": "en", "title": "Topological Interference Management with Alternating Connectivity", "pdf_url": "http://arxiv.org/pdf/1302.4020v1"}
{"id": "1312.4231", "abstract": "Attribute reduction is a basic issue in knowledge representation and data mining. Rough sets provide a theoretical foundation for the issue. Matroids generalized from matrices have been widely used in many fields, particularly greedy algorithm design, which plays an important role in attribute reduction. Therefore, it is meaningful to combine matroids with rough sets to solve the optimization problems. In this paper, we introduce an existing algebraic structure called dependence space to study the reduction problem in terms of matroids. First, a dependence space of matroids is constructed. Second, the characterizations for the space such as consistent sets and reducts are studied through matroids. Finally, we investigate matroids by the means of the space and present two expressions for their bases. In a word, this paper provides new approaches to study attribute reduction.", "lang": "en", "title": "Dependence space of matroids and its application to attribute reduction", "pdf_url": "http://arxiv.org/pdf/1312.4231v2"}
{"id": "1512.00344", "abstract": "This paper is concerned with stochastic SIR and SEIR epidemic models on random networks in which individuals may rewire away from infected neighbors at some rate ω (and reconnect to non-infectious individuals with probability α or else simply drop the edge if α=0), so-called preventive rewiring. The models are denoted SIR-ω and SEIR-ω, and we focus attention on the early stages of an outbreak, where we derive expression for the basic reproduction number R_0 and the expected degree of the infectious nodes E(D_I) using two different approximation approaches. The first approach approximates the early spread of an epidemic by a branching process, whereas the second one uses pair approximation. The expressions are compared with the corresponding empirical means obtained from stochastic simulations of SIR-ω and SEIR-ω epidemics on Poisson and scale-free networks. Without rewiring of exposed nodes, the two approaches predict the same epidemic threshold and the same E(D_I) for both types of epidemics, the latter being very close to the mean degree obtained from simulated epidemics over Poisson networks. Above the epidemic threshold, pairwise models overestimate the value of R_0 computed from simulations, which turns out to be very close to the one predicted by the branching process approximation. When exposed individuals also rewire with α > 0 (perhaps unaware of being infected), the two approaches give different epidemic thresholds, with the branching process approximation being more in agreement with simulations.", "lang": "en", "title": "A network epidemic model with preventive rewiring: comparative analysis\n  of the initial phase", "pdf_url": "http://arxiv.org/abs/1512.00344v3"}
{"id": "1604.06187", "abstract": "Evolutionary algorithms have been widely studied from a theoretical perspective. In particular, the area of runtime analysis has contributed significantly to a theoretical understanding and provided insights into the working behaviour of these algorithms. We study how these insights into evolutionary processes can be used for evolutionary art. We introduce the notion of evolutionary image transition which transfers a given starting image into a target image through an evolutionary process. Combining standard mutation effects known from the optimization of the classical benchmark function OneMax and different variants of random walks, we present ways of performing evolutionary image transition with different artistic effects.", "lang": "en", "title": "Evolutionary Image Transition Based on Theoretical Insights of Random\n  Processes", "pdf_url": "http://arxiv.org/pdf/1604.06187v1"}
{"id": "1604.08243", "abstract": "Recent years have witnessed several initiatives on enabling Internet access to the next three billion people. Access to the Internet necessarily translates to access to its services. This means that the goal of providing Internet access requires ac- cess to its critical service infrastructure, which are currently hosted in the cloud. However, recent works have pointed out that the current cloud centric nature of the Internet is a fundamental barrier for Internet access in rural/remote areas as well as in developing regions. It is important to explore (low cost) solutions such as micro cloud infrastructures that can provide services at the edge of the network (potentially on demand), right near the users. In this paper, we present Cloudrone- a preliminary idea of deploying a lightweight micro cloud infrastructure in the sky using indigenously built low cost drones, single board computers and lightweight Operating System virtualization technologies. Our paper lays out the preliminary ideas on such a system that can be instantaneously deployed on demand. We describe an initial design of the Cloudrone and provide a preliminary evaluation of the proposed system mainly focussed on the scalability issues of supporting multiple services and users.", "lang": "en", "title": "Cloudrone: Micro Clouds in the Sky", "pdf_url": "http://arxiv.org/pdf/1604.08243v1"}
{"id": "1605.06560", "abstract": "As the complexity of deep neural networks (DNNs) trend to grow to absorb the increasing sizes of data, memory and energy consumption has been receiving more and more attentions for industrial applications, especially on mobile devices. This paper presents a novel structure based on functional hashing to compress DNNs, namely FunHashNN. For each entry in a deep net, FunHashNN uses multiple low-cost hash functions to fetch values in the compression space, and then employs a small reconstruction network to recover that entry. The reconstruction network is plugged into the whole network and trained jointly. FunHashNN includes the recently proposed HashedNets as a degenerated case, and benefits from larger value capacity and less reconstruction loss. We further discuss extensions with dual space hashing and multi-hops. On several benchmark datasets, FunHashNN demonstrates high compression ratios with little loss on prediction accuracy.", "lang": "en", "title": "Functional Hashing for Compressing Neural Networks", "pdf_url": "http://arxiv.org/pdf/1605.06560v1"}
{"id": "1607.01400", "abstract": "We propose a clustering-based iterative algorithm to solve certain optimization problems in machine learning, where we start the algorithm by aggregating the original data, solving the problem on aggregated data, and then in subsequent steps gradually disaggregate the aggregated data. We apply the algorithm to common machine learning problems such as the least absolute deviation regression problem, support vector machines, and semi-supervised support vector machines. We derive model-specific data aggregation and disaggregation procedures. We also show optimality, convergence, and the optimality gap of the approximated solution in each iteration. A computational study is provided.", "lang": "en", "title": "An Aggregate and Iterative Disaggregate Algorithm with Proven Optimality\n  in Machine Learning", "pdf_url": "http://arxiv.org/abs/1607.01400v1"}
{"id": "1609.03234", "abstract": "Counterfactual Regret Minimization (CFR) is the most popular iterative algorithm for solving zero-sum imperfect-information games. Regret-Based Pruning (RBP) is an improvement that allows poorly-performing actions to be temporarily pruned, thus speeding up CFR. We introduce Total RBP, a new form of RBP that reduces the space requirements of CFR as actions are pruned. We prove that in zero-sum games it asymptotically prunes any action that is not part of a best response to some Nash equilibrium. This leads to provably faster convergence and lower space requirements. Experiments show that Total RBP results in an order of magnitude reduction in space, and the reduction factor increases with game size.", "lang": "en", "title": "Reduced Space and Faster Convergence in Imperfect-Information Games via\n  Regret-Based Pruning", "pdf_url": "http://arxiv.org/pdf/1609.03234v1"}
{"id": "1703.07822", "abstract": "We consider the problem of a robot learning the mechanical properties of objects through physical interaction with the object, and introduce a practical, data-efficient approach for identifying the motion models of these objects. The proposed method utilizes a physics engine, where the robot seeks to identify the inertial and friction parameters of the object by simulating its motion under different values of the parameters and identifying those that result in a simulation which matches the observed real motions. The problem is solved in a Bayesian optimization framework. The same framework is used for both identifying the model of an object online and searching for a policy that would minimize a given cost function according to the identified model. Experimental results both in simulation and using a real robot indicate that the proposed method outperforms state-of-the-art model-free reinforcement learning approaches.", "lang": "en", "title": "Information-theoretic Model Identification and Policy Search using\n  Physics Engines with Application to Robotic Manipulation", "pdf_url": "http://arxiv.org/pdf/1703.07822v1"}
{"id": "1008.2277", "abstract": "This paper deals with chain graphs under the classic Lauritzen-Wermuth-Frydenberg interpretation. We prove that the regular Gaussian distributions that factorize with respect to a chain graph G with d parameters have positive Lebesgue measure with respect to ℝ^d, whereas those that factorize with respect to G but are not faithful to it have zero Lebesgue measure with respect to ℝ^d. This means that, in the measure-theoretic sense described, almost all the regular Gaussian distributions that factorize with respect to G are faithful to it.", "lang": "en", "title": "Faithfulness in Chain Graphs: The Gaussian Case", "pdf_url": "http://arxiv.org/pdf/1008.2277v1"}
{"id": "1009.0558", "abstract": "This paper proposes a robust control method based on sliding mode design for two-level quantum systems with bounded uncertainties. An eigenstate of the two-level quantum system is identified as a sliding mode. The objective is to design a control law to steer the system's state into the sliding mode domain and then maintain it in that domain when bounded uncertainties exist in the system Hamiltonian. We propose a controller design method using the Lyapunov methodology and periodic projective measurements. In particular, we give conditions for designing such a control law, which can guarantee the desired robustness in the presence of the uncertainties. The sliding mode control method has potential applications to quantum information processing with uncertainties.", "lang": "en", "title": "Sliding Mode Control of Two-Level Quantum Systems", "pdf_url": "http://arxiv.org/abs/1009.0558v2"}
{"id": "1206.1948", "abstract": "Fundamental limits of the cognitive interference channel (CIC) with two pairs of transmitter-receiver has been under exploration for several years. In this paper, we study the discrete memoryless cognitive interference channel (DM-CIC) in which the cognitive transmitter non-causally knows the message of the primary transmitter. The capacity of this channel is not known in general; it is only known in some special cases. Inspired by the concept of less noisy broadcast channel (BC), in this work we introduce the notion of less noisy cognitive interference channel. Unlike BC, due to the inherent asymmetry of the cognitive channel, two different less noisy channels are distinguishable; these are named the primary-less-noisy and cognitive-less-noisy channels. We derive capacity region for the latter case, by introducing inner and outer bounds on the capacity of the DM-CIC and showing that these bounds coincide for the cognitive-less-noisy channel. Having established the capacity region, we prove that superposition coding is the optimal encoding technique.", "lang": "en", "title": "The Capacity of Less Noisy Cognitive Interference Channels", "pdf_url": "http://arxiv.org/pdf/1206.1948v2"}
{"id": "1505.06450", "abstract": "Growth dynamic of real networks because of emerging complexities is an open and interesting question. Indeed it is not realistic to ignore history impact on the current events. The mystery behind that complexity could be in the role of history in some how. To regard this point, the average effect of history has been included by a kernel function in differential equation of Barabasi Albert (BA) model . This approach leads to a fractional order BA differential equation as a generalization of BA model. As opposed to unlimited growth for degree of nodes, our results show that over time the memory impact will cause a decay for degrees. This gives a higher chance to younger members for turning to a hub. In fact in a real network, there are two competitive processes. On one hand, based on preferential attachment mechanism nodes with higher degree are more likely to absorb links. On the other hand, node history through aging process prevents new connections. Our findings from simulating a network grown by considering these effects also from studying a real network of collaboration between Hollywood movie actors conforms the results and significant effects of history and time on dynamic.", "lang": "en", "title": "History effects on network growth", "pdf_url": "http://arxiv.org/pdf/1505.06450v1"}
{"id": "1606.00541", "abstract": "In this paper, we investigate GPU based parallel triangular solvers systematically. The parallel triangular solvers are fundamental to incomplete LU factorization family preconditioners and algebraic multigrid solvers. We develop a new matrix format suitable for GPU devices. Parallel lower triangular solvers and upper triangular solvers are developed for this new data structure. With these solvers, ILU preconditioners and domain decomposition preconditioners are developed. Numerical results show that we can speed triangular solvers around seven times faster.", "lang": "en", "title": "Parallel Triangular Solvers on GPU", "pdf_url": "http://arxiv.org/pdf/1606.00541v1"}
{"id": "1611.03006", "abstract": "An increasing number of individuals are turning to Direct-To-Consumer (DTC) genetic testing to learn about their predisposition to diseases, traits, and/or ancestry. DTC companies like 23andme and Ancestry.com have started to offer popular and affordable ancestry and genealogy tests, with services allowing users to find unknown relatives and long-distant cousins. Naturally, access and possible dissemination of genetic data prompts serious privacy concerns, thus motivating the need to design efficient primitives supporting private genetic tests. In this paper, we present an effective protocol for privacy-preserving genetic relatedness test (PPGRT), enabling a cloud server to run relatedness tests on input an encrypted genetic database and a test facility's encrypted genetic sample. We reduce the test to a data matching problem and perform it, privately, using searchable encryption. Finally, a performance evaluation of hamming distance based PP-GRT attests to the practicality of our proposals.", "lang": "en", "title": "Privacy-Preserving Genetic Relatedness Test", "pdf_url": "http://arxiv.org/pdf/1611.03006v2"}
{"id": "1105.3427", "abstract": "This paper proposes real-time sequential convex programming (RTSCP), a method for solving a sequence of nonlinear optimization problems depending on an online parameter. We provide a contraction estimate for the proposed method and, as a byproduct, a new proof of the local convergence of sequential convex programming. The approach is illustrated by an example where RTSCP is applied to nonlinear model predictive control.", "lang": "en", "title": "Real-Time Sequential Convex Programming for Optimal Control Applications", "pdf_url": "http://arxiv.org/pdf/1105.3427v1"}
{"id": "1206.6177", "abstract": "This paper deals with the structural analysis problem of dynamic lumped process high-index DAE models. We consider two methods for index reduction of such models by differentiation: Pryce's method and the symbolic differential elimination algorithm rifsimp. Discussion and comparison of these methods are given via a class of fundamental process simulation examples. In particular, the efficiency of the Pryce method is illustrated as a function of the number of tanks in process design.", "lang": "en", "title": "Structural analysis of high-index DAE for process simulation", "pdf_url": "http://arxiv.org/pdf/1206.6177v1"}
{"id": "1605.08838", "abstract": "We study dueling bandits with weak utility-based regret when preferences over arms have a total order and carry observable feature vectors. The order is assumed to be determined by these feature vectors, an unknown preference vector, and a known utility function. This structure introduces dependence between preferences for pairs of arms, and allows learning about the preference over one pair of arms from the preference over another pair of arms. We propose an algorithm for this setting called Comparing The Best (CTB), which we show has constant expected cumulative weak utility-based regret. We provide a Bayesian interpretation for CTB, an implementation appropriate for a small number of arms, and an alternate implementation for many arms that can be used when the input parameters satisfy a decomposability condition. We demonstrate through numerical experiments that CTB with appropriate input parameters outperforms all benchmarks considered.", "lang": "en", "title": "Dueling Bandits with Dependent Arms", "pdf_url": "http://arxiv.org/pdf/1605.08838v2"}
{"id": "3298748", "abstract": "L'objectif de ce travail est de développer des méthodes d'apprentissage profond pour l'analyse et l'interprétation automatique des émotions à partir des mouvements et de la posture du corps humain. A partir du jeu de données BOLD nous avons crée un modèle basé sur les LSTM afin de détecter les émotions.", "publication_date": "2021.07.23", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03298748/file/RJCIA_2021_paper_24.pdf", "lang": "fr"}
{"id": "3298747", "abstract": "Dans le domaine bancaire, la détection de fraudes doit être explicable et le modèle de décision compréhensible. Cela justifie un apprentissage direct de règles. CN2 et RIPPER sont comparés sur différents datasets.", "publication_date": "2021.07.23", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03298747/file/RJCIA_2021_paper_23.pdf", "lang": "fr"}
{"id": "3282727", "abstract": "Les systèmes de Calcul Haute Performance font face à de plus en plus de variations dans leur comportement, que ce soit en performance, consommation d'énergie, etc. Cette imprédictiblité nous amène à considérer une approche autonomique à leur gestion, utilisant des boucles de rétro-action, et des outils de l'automatique. Nous présentons une application de cette approche dans le cas de CiGri, un intergiciel exploitant les ressources libres d'une grille de calculs, dans le but d'en maximiser l'utilisation, en y injectant des tâches best-effort. Nous nous focalisons ici sur le problème d'éviter que ces dernières ne surchargent le serveur de fichiers distribué.", "publication_date": "2021.07.09", "pdf_url": "https://hal.inria.fr/hal-03282727/file/COMPAS21_Guilloteau_collecte_ressources_libres_approche_autonomique.pdf", "lang": "fr"}
{"id": "3317641", "abstract": "On considère des simulations distribuées sur un ensemble de ressources de calcul. Elles sont composées d'un grand nombre d'entités informatiques communicantes en perpétuelle évolution (objets, acteurs, agents. . .). À l'aide d'un algorithme fourmi nous détectons les organisations présentes afin de rapprocher par migration les entités qui les constituent, en respectant l'équilibrage de charge. Nous utilisons un graphe dynamique de communication pour modéliser les applications. Plusieurs colonies de fourmis, chacune d'une couleur distincte représentant une ressource (ex : un processeur), entrent en compétition pour marquer les sommets du graphe en utilisant des phéromones colorées. Lorsque la couleur d'un sommet change, cela signifie que l'entité correspondante peut éventuellement migrer, ceci en fonction des contraintes de l'application.", "publication_date": "2021.08.06", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03317641/file/Simulations_distribuOes_par_un_algorithm.pdf", "lang": "fr"}
{"id": "3292923", "abstract": "Depuis le début de la pandémie de COVID-19, de nombreux pays ont adopté l'enseignement en ligne comme alternative aux cours en présentiel. Cette situation a accentué la prise de conscience de l'importance d'analyser les données d'apprentissage laissées par les élèves, pour améliorer et évaluer le processus d'apprentissage. Cet article expose les résultats d'une étude conduite sur une classe de 26 élèves de deuxième année du cycle ingénieur d'un établissement supérieur au Maroc, suivant tous un cours en modalité mixte sur la plateforme Moodle. Cette étude porte sur un outil destiné aux enseignants ainsi qu'aux élèves afin de faciliter le suivi et le contrôle du processus d'apprentissage, les résultats montrent que l'outil a permis d'améliorer l'engagement et le taux de réussite des élèves. Mots-clés : Visualisation de l'information, analyse de l'apprentissage, tableau de bord, apprentissage autorégulé, environnements d'apprentissage en ligne.", "publication_date": "2021.07.23", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03292923/file/EIAH2021_Safsouf_et_al.pdf", "abstract_en": "Since the beginning of coronavirus pandemic (COVID-19), many countries have adopted online education as an alternative to traditional classroom courses. As a result, a new awareness has emerged of the importance of analyzing the learning data collected from students to improve and evaluate the learning process. This article presents the results of a study conducted on a group of 26 second-year engineering students from a higher education institution in Morocco, all of them taking a blended-mode course on the Moodle platform. This study focuses on a tool for teachers and students to help track and monitor the learning process, the results show that this tool improved student engagement and success rates.", "lang": "fr"}
{"id": "3292753", "abstract": "La fluence en lecture à haute voix est couramment évaluée en mesurant le nombre de mots correctement lus par minute. Cette évaluation se fait au détriment de l’expressivité et du phrasé, pourtant nécessaire à la compréhension, mais complexes à évaluer car très subjectifs. Nous proposons ici d’évaluer automatiquement les quatre dimensions de la fluence en lecture : décodage, vitesse, phrasé et expressivité. Cet outil s’appuie sur une analyse automatique des paramètres acoustiques, notamment par comparaison à de multiples lecteurs experts, et sur une échelle d’évaluation subjective adaptée pour le français. Nous avons pu montrer que cet outil est plus précis et consistant que des juges humains. Il permet de plus de s’affranchir de la variabilité inter-juges. Il est donc particulièrement adapté à un suivi longitudinal des enfants. Cet outil a été utilisé pour évaluer les lectures de 49 enfants suivis du CE1 au CM1. Ces analyses ont permis de mettre en évidence les profils de développement de chaque dimension de la fluence en lecture.", "publication_date": "2021.07.23", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03292753/file/EIAH2021_Godde_et_al.pdf", "abstract_en": "Reading fluency is usually assessed with the number of words correctly read in a minute. Expressivity and phrasing are then omitted, probably because these dimensions are more subjective and complex to assess. We propose here a new tool to assess the four dimensions of reading fluency : pace, smoothness, phrasing and expressivity. This tool use an automatic analysis of acoustic features and multiple expert references to predict the acore to a subjective scale. We show that this tool is valid, precise and more consistent than human raters. This tool is then well adapted to multiple assessments. We used it to assess the reading fluency of 49 young readers three times in CE1, CE2 and CM1. These analyses enable us to caracterize the development patterns of the four dimensions of reading fluency.", "lang": "fr"}
{"id": "3313637", "abstract": "Avec cette communication l’auteur propose un nouveau langage musical qui se base sur la description de l’évolution du degré d’une ligne mélodique. L’idée est celle de faire abstraction de l’aspect harmonique qui pourra être décrit dans un deuxième moment. L’œuvre musicale sera alors le résultat de la contribution de ces deux aspects distincts : d’une part un modèle de mélodie faisant abstraction de la notion de hauteur, mais se basant plutôt sur une notion de degré et son évolution temporaire ; de l’autre une structure harmonique représentée par une séquence d’accords et de gammes associées qui donneront du sens aux degrés définis dans le modèle mélodique. Une implémentation informatique sera également proposée.", "publication_date": "2021.08.04", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03313637/file/article_le_langage_DBLV4.pdf", "lang": "fr"}
{"id": "3313639", "abstract": "Cet article présente Synopsis Seriation (2021), une création musicale générée avec l’aide de l’ordinateur. L’idée centrale consiste à ré-organiser des fragments de pistes dans une œuvre multicanal pré-existante afin de produire un flux stéréo. Nous appelons “sériation” la recherche de la plus grande similarité de timbre entre fragments successifs dans chaque canal ainsi qu’entre canal gauche et canal droite. Or, puisque le nombre de permutations d’un ensemble est la factorielle de son cardinal, l’espace des séquences possibles est trop vaste pour être exploré directement par l’humain. Là contre, nous formalisons la sériation comme un problème d’optimisation NP-complet de type “voyageur de commerce” et présentons un algorithme évolutionniste qui en donne une solution approximée. Dans ce cadre, nous définissons la dissimilarité de timbre entre deux fragments à partir d’outils issus de l’analyse en ondelettes (diffusion temps-fréquence) ainsi que de la géométrie de l’information (divergence de Jensen–Shannon). Pour cette œuvre, nous avons exécuté l’algorithme de sériation sur un corpus de quatre œuvres de Florian Hecker, comprenant notamment Formulation (2015). La maison de disques Editions Mego, Vienne, a publié Synopsis Seriation en format CD, assorti d’un livret d’infographies sur la diffusion temps- fréquence conçu en partenariat avec le studio de design NORM, Zurich.", "publication_date": "2021.08.04", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03313639/file/lostanlen2021jim_revised.pdf", "lang": "fr"}
{"id": "3313612", "abstract": "Nous présentons dans cet article un projet work in progress avec live patching au sein d’une collaboration avec le Conservatoire de Saint-Denis. Après avoir utilisé le logiciel Kiwi pour cette pratique, nous migrons vers Pure Data et Faust en poursuivant notre conception du live patching, notamment l’approche « commencer du zéro ». C’est-à-dire, construire collaborativement et en temps réel un patch sans aucun a priori, à partir d’un document vide. Cette pratique a été appliquée au sein d’un atelier avec le Conservatoire de Saint-Denis, aboutissant sur une représentation publique le 29 mars 2021 à la Maison des Sciences de l’Homme Paris Nord. Pour cette restitution, nous avons choisi de présenter une séance construite à partir des nos ateliers avec live patching. Plutôt que de coder en temps réel, les participants ont joué avec un patch déjà créé, mais pouvant interagir avec des diapositives OSC et avec leurs instruments musicaux", "publication_date": "2021.08.04", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03313612/file/Svidzinski_Live_patching_collaboratif_vers_une_mediation_inclusive_avec_l_informatique_musicale.pdf", "lang": "fr"}
{"id": "3320332", "abstract": "Cet article aborde la reconnaissance d’entités nommées (NER) appliquée aux textes historiques obtenus à partir du traitement d’images numériques de journaux à l’aide de tech-niques de reconnaissance optique de caractères (OCR). Nous soutenons que le principal défi pour cette tâche est que le processus OCR produit des textes contenant entre autres des fautes d’orthographe et des erreurs de syntaxes. De plus, des variations sémantiques peuvent être présentes dans les documents anciens, ce qui a un impact sur les performances de la reconnaissance d’entités nommées. Nous menons une évaluation comparative à l’état de l’art de deux ensembles de données historiques en allemand et en français, et nous proposons un modèle basé sur une pile hiérarchique de couches Transformer pour aborder la reconnaissance d’entités nommées dans des données historiques. Nos résultats montrent que le modèle proposé améliore clairement les résultats sur les deux ensembles de données", "publication_date": "2021.08.15", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03320332/file/main%281%29.pdf", "abstract_en": "This paper tackles the task of NER applied to historical texts obtained from processing digital images of news papers using OCR techniques. The main challenge for this task is that the OCR process leads to misspellings and linguistic errors in the output text, which can impact the performance of the NER. We conduct a comparative evaluation on two historical datasets in German and French against previous state-of-the-art models, and we propose a model based ona hierarchical stack of Transformers to approach the NER task for historical data. Our findings show that the proposed model clearly improves the results on both historical data sets", "lang": "fr"}
{"id": "3329514", "abstract": "Dans cet article, nous montrons comment l'utilisation conjointe d'une technique d'alignement de phrases parallèles à la demande et d'estimation de modèles de traduction à la volée permet une réduction en temps très notable (jusqu'à 93% dans nos expériences) par rapport à un système à l'état de l'art, tout en offrant un compromis en termes de qualité très intéressant dans certaines configurations. En particulier, l'exploitation immédiate de documents traduits permet de compenser très rapidement l'absence d'un corpus de développement.", "publication_date": "2021.08.31", "pdf_url": "https://hal.archives-ouvertes.fr/hal-01908367/file/F14-2002.pdf", "lang": "fr"}
{"id": "3321348", "abstract": "Le cerveau humain, pour allouer de manière optimale les ressources attentionnelles limitées dont il dispose, supprime ou renforce l’activation de circuits neuronaux : il implémente des heuristiques. Dans une approche novatrice, nous proposons d’utiliser l’apprentissage par renforcement inverse pour caractériser la dynamique d’activation de ces réseaux. Un protocole expérimental est proposé, et les données collectées devraient permettre, à terme, de vérifier cette démarche.", "publication_date": "2021.08.17", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03321348/file/actes_CNIA_CH_PFIA2021%20-%20somon.pdf", "abstract_en": "The human brain possesses limited attentional resources and requires heuristics in order to optimise their allocation through neural networks reinforcement. We propose here that using inverse reinforcement learning is an interesting approach to characterize the dynamic activation of these networks. We present an experimental setting aiming at this characterization, and we propose that data collection will comfort this position.", "lang": "fr"}
{"id": "3297018", "abstract": "L'Institut Français de Bioinformatique (IFB) propose différents services pour le traitement des données des sciences de la vie, en partie basés sur une fédération de clouds académiques. Le portail Biosphère (https://biosphere.france-bioinformatique.fr) fournit plusieurs interfaces pour simplifier l’usage du cloud de l’IFB : le catalogue RAINBio des environnements modèles (appliances), un tableau de bord pour gérer les déploiements et un registre des données publiques disponibles. La fédération IFB-Biosphère, initiée fin 2016, comporte 5 400 cœurs et 27 téraoctets de mémoire, répartis entre 6 sites basés sur Openstack, fédérés avec le système Nuvla. En plus des composants de base, d'autres plus spécifiques comme Manila pour la fourniture de volumes partagés en mode fichier, sont requis pour la majorité des applications bioinformatiques. La gestion des utilisateurs repose sur les identifiants institutionnels de la fédération d’identités eduGAIN, avec un proxy \"keycloack\" et des clients OpenID Connect. Les appliances bioinformatiques proposent de nombreux outils courants pour l’analyse de données biologiques, 33 sont actuellement publiées dans le catalogue RAINBio. Ces environnements fournissent des outils comme \"conda\", \"docker\" ou \"ansible\"; des interfaces scientifiques de haut-niveau (portails web Rstudio ou Jupyter Notebook), ou un bureau graphique à distance. Certains environnements comprennent plusieurs composants reposant sur autant de machines virtuelles ou conteneurs. Le quota de base, extensible, permet de déployer des VMs, avec jusqu’à 128 cœurs et 3 To de RAM. Le cloud IFB-Biosphère est utilisé pour des analyses scientifiques pouvant être intensives (4 000 cœurs), et par de nombreuses sessions de formation, écoles scientifiques, cursus de masters universitaires, workshops ou hackathons.", "publication_date": "2021.07.23", "pdf_url": "https://hal-cnrs.archives-ouvertes.fr/hal-03297018/file/paper154_article_rev5288_20191030_162623.pdf", "lang": "fr"}
{"id": "3339652", "abstract": "Cet article traite du suivi de pose direct basé modèle 3D. Nous considérons la transformation d’images omnidirectionnelles en Mélange de Gaussiennes Photométriquesn (MGP) comme primitives directes. Les contributions sont d’adapter l’optimisation de pose aux caméras omnidirectionnelles et de repenser les règles d’initialisation et d’optimisation du paramètre d’extension du MGP. Plusieurs évaluations montrent que cette approche augmente la taille du domaine de convergence. L’application à des images acquises avec un robot mobile placé dans un environnement urbain, représenté par un grand nuage de points 3D coloré, montre une robustesse significative aux grands mouvements inter-images par rapport aux approches directes qui utilisent uniquement l’intensité des pixels", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339652/file/Photometric_Gaussian_Mixtures_for_Direct_Virtual_Visual_Servoing_of_Omnidirectional_Camera.pdf", "lang": "fr"}
{"id": "3339664", "abstract": "Le défi de la segmentation d’instance a été exploré principalement avec des images rectilinéaires. Cependant, la segmentation d’instance dans des images fisheye implique des difficultés supplémentaires et n’a pas encore été complètement explorée. Un modèle CNN capable de fonctionner aussi bien sur des données rectilinéaires que sur des données fisheye sans modification permet d’envisager de multiples applications, et possède des avantages en terme de puissance de calcul requise, ce qui se révèle être un aspect crucial pour les systèmes temps réels, comme ceux embarqués en environnement transport. Dans cet article, nous démontrons qu’un ensemble simple d’augmentations fisheye permet d’améliorer les performances sur des images fisheye tout en conservant celles obtenues sur des images rectilinéaires.", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339664/file/ORASIS_2021_compressed_final.pdf", "lang": "fr"}
{"id": "3339687", "abstract": "Ce travail est réalisé dans le cadre du projet AniMov qui consiste à mettre en place un système de surveillance vidéo des comportements des animaux en situation d’élevage. L’objectif principal du projet est de fournir aux éleveurs un outil d’analyse capable de produire des indicateurs précis pour piloter l’alimentation et la reproduction mais aussi de détecter les cycles d’activité et les situations anormales. Notre système d’analyse automatique repose sur un ensemble de caméras placées dans l’enclos ou le bâtiment d’élevage et des algorithmes d’apprentissage machine. Le travail présenté dans cet article constitue la première partie de ce projet : la détection et le suivi descaprins à travers les vidéos. Nous avons mis en œuvre une méthode de suivi basée sur la détection. Pour la détection, nous avons utilisé YOLO v4, une architecture de détection à une étape, après une comparaison avec le modèle Faster R-CNN. Nous avons utilisé une base de 796 images dont 646 pour l’entraînement et 150 pour le test. Ensuite le filtre de Kalman, couplé avec l’algorithme hongrois, est appliqué pour le suivi. L’évaluation de notre méthode de détection sur les données de test nous donne une précision moyenne de 86.74% pour la classe chevre_debout et 90.56% pour la classe chevre_couche.", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339687/file/article_detection_suivi.pdf", "lang": "fr"}
{"id": "3339670", "abstract": "La segmentation des vaisseaux hépatiques est une tâche trés difficile en raison de la petite taille et de la complexité du réseau vasculaire. Dans cet article, nous proposons une étude comparative originale de plusieurs modèles d’apprentissage profond combinés à des filtres de rehaussement (algorithmes Jerman, Frangi, Sato et RORPO) comme étape de prétraitement. Les modèles 3-D U-Net, 3-D Dense U-Net et 3-D MultiRes U-Net ont été testés sur des images tomodensitométriques pour extraire les réseaux vasculaires avec et sans prétraitement sur des volumes hépatiques complets et sur des slabs (groupes de coupes 2-D). Les modèles ont été testés sur la base de données publique IRCAD et le 3-D Dense U-Net a obtenu le meilleur coefficient Dice sur les données prétraitées (avec le filtre Jerman en particulier), par rapport aux données brutes. En plus de cette analyse numérique, nous proposons une inspection visuelle des résultats de segmentation, qui confirment la précision de ce modèle profond basé sur des filtres de rehaussement vasculaire", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339670/file/ORASIS_2021_Segmentation_vaisseaux_foie1.pdf", "lang": "fr"}
{"id": "3292785", "abstract": "De plus en plus, les universités et les écoles d'ingénieurs tendent à adopter une approche par compétences et à proposer aux étudiants la personnalisation de leur cursus pour correspondre à leurs attentes de carrière, au détriment de cursus prédéfinis. Une telle personnalisation de cursus soulève d'importantes problématiques, comme une répartition convenable des compétences en son sein, l'assurance que les étudiants conservent bien leurs acquis, l'ordonnancement des cours entre eux ou encore gérer la non validation d'un cours dans le cursus. Ce papier pose les fondements théoriques de ce nouveau problème qu'est la personnalisation d'un cursus académique avec érosion des compétences, en propose les toutes premières modélisation et tentative de résolution.", "publication_date": "2021.07.24", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03292785/file/EIAH2021_Lebis_et_al_A.pdf", "abstract_en": "Nowadays in education, more and more universities and en- gineering schools tend to remove predefined specialization curriculum in order to promote student ability to construct their own personalized training, matching their career goal. This leads to several major problems such as knowledge dissemination, courses ordering to satisfy knowledge prerequisite, courses congestion and recommendation, or even handling student’s non-validation of courses in the curriculum. In this paper, we introduce an ecological definition of the personalized university curricu- lum organization problem.", "lang": "fr"}
{"id": "3339624", "abstract": "La segmentation des vaisseaux sanguins est une tâche difficile du fait de leur finesse, tortuosité et connectivité complexe. Des méthodes par apprentissage profond ont été proposées pour répondre à ce problème, mais nécessitent de larges jeux de données (un pour chaque nouvelle application), ce qui est très difficile à obtenir pour les réseaux vasculaires. Dans ce papier, plutôt que d'apprendre à segmenter, nous proposons d''apprendre un terme de régularisation reconnecteur. Ainsi, ce terme peut se généraliser plus facilement que les modèles de segmentation appris par apprentissage profond et peut être facilement injecté dans des schémas d'optimisation variationnelles pour détecter des réseaux vasculaires de différents jeux donnés sans nécessiter de nouvelles annotations. Nous montrons que notre approche permet de mieux préserver la connectivité des réseaux vasculaires que certains termes de régularisations classiques. Enfin, nous montrons le pouvoir de généralisation de notre terme de reconnexion en l'appliquant à d'autres types de données.", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339624/file/ORASIS_Sophie.pdf", "lang": "fr"}
{"id": "3290040", "abstract": "Pour faciliter l’appropriation des jeux sérieux d’apprentissage par les enseignants, nous étudions les méthodes de conception qui leur laissent une grande place à la fois dans les phases de conception et d’utilisation : les méthodes de méta-design. Dans ce cadre, nous nous intéressons au jeu sérieux Blockly Maze destiné à l’apprentissage de la programmation. Notre objectif est ainsi de proposer des modèles et outils de conception de niveaux et de scénarios pour ce jeu et de fournir à l’enseignant des indicateurs de suivi lui permettant de s’approprier et d’adapter le jeu en fonction des usages observés. Dans cet article, nous détaillons les premiers apports de cette étude (modèles, outils, in- dicateurs de suivi) et les premiers résultats de nos observations sur ces contributions.", "publication_date": "2021.07.19", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03290040/file/EIAH2021_Marne_et_al.pdf", "abstract_en": "To support the appropriation of serious learning games by teachers, we are studying design methods that centers them in both the design and use phases: meta-design methods. Our objective is to propose models and tools for designing levels and scenarios for Blockly Maze and to provide the teacher with monitoring indicators allowing him/her to appropriate and adapt the game according to the observed uses. In this article, we detail the first contributions of this study (models, tools) and the first results of our observations on these contributions.", "lang": "fr"}
{"id": "3290068", "abstract": "Cette étude vise à identifier les représentations sociales de l’analytique des apprentissages avec le numérique chez différents acteurs de l’éducation. Nous avons analysé les réponses de 286 participants à un questionnaire en utilisant la technique d’Évocation Hiérarchique et les résultats montrent que pour la majorité d’entre eux, les aspects les plus importants pour déterminer le domaine sont : apprentissage, données, analyse, suivi et traces. De plus, nous avons observé des variations entre différents sous-groupes de parties prenantes.", "publication_date": "2021.07.22", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03290068/file/EIAH2021_MoraisCanellas_et_al.pdf", "abstract_en": "This study aims to identify the social representations of the Learning Analytics domain among different education stakeholders. We analyzed the responses of 286 participants to a questionnaire using the Hierarchical Evocation technique. Results show that for the majority of them the most important aspects to determine the domain are: learning, data, analysis, tracking and traces. In addition, we observed variations between different subgroups of stakeholders.", "lang": "fr"}
{"id": "3339685", "abstract": "Le démélangeage hyperspectral consiste à extraire des endmembers puis déterminer l’abondance des endmembers dans chaque pixel de l’image. Dans cet article, nous présentons trois méthodes de l’état de l’art pour extraire les endmembers. Ces méthodes sont habituellement utilisées dans le domaine de la télédétection. Elles sont ici appliquées à un nouveau domaine : le patromoine culturel. Les méthodes sont testées sur une base de données peinture. Nous comparons et analysons les résultats et performances de ces méthodes sur ce type de données", "publication_date": "2021.09.09", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03339685/file/ORASIS2021_12thJuly.pdf", "lang": "fr"}
{"id": "3298729", "abstract": "Cet article présente les travaux qui serviront de base à la réalisation d'un modèle d'habitat intelligent adaptatif multi-résidents centré utilisateur. Nous y présentons en premier lieu le contexte qui nous amène à proposer ce projet, puis nous dressons un état de l'art des travaux reliés à notre projet. Nous concluons enfin sur le positionnement de notre démarche par rapport à l'existant ainsi que sur une discussion sur les perspectives en cours et envisagées.", "publication_date": "2021.07.23", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03298729/file/RJCIA_2021_paper_11.pdf", "lang": "fr"}
{"id": "3356549", "abstract": "La représentation et la gestion d'informations dans le cadre des systèmes complexes, où les flux de données sont importants, posent bien souvent problème, en particulier lorsque des prises de décisions sont souhaitées. Cela est d'autant plus difficile que ces informations sont imprécises et incertaines. En Entomologie Médico-Légale, un expert, déterminant la date de la mort d'une victime retrouvée dans un écosystème complexe, doit ainsi traiter ce type d'informations imparfaites tout en restant objectif et prudent. Pour résoudre ces problématiques, un système informatique d'aide à la décision a été mis en oeuvre. Le modèle de croyances tranférables (MCT) est ensuite utilisé pour compiler les résultats de ce système.", "publication_date": "2021.09.28", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03356549/file/FDC_EGC08-1.pdf", "lang": "fr"}
{"id": "3359983", "abstract": "Ce papier propose une approche de recherche d’information basée sur l’utilisation d’une structure conceptuelle pour indexer les documents. La structure conceptuelle est hiérarchique. Elle est représentée par un sous-arbre pondéré. Un sous-arbre est obtenu d’abord en projetant document et requête sur une ressource conceptuelle externe, puis en appliquant une méthode de complétion via des nœuds intermédiaires extraits de cette ressource en vue d’avoir une représentation hiérarchique. Dans cette approche, l’évaluation des requêtes se fait par la comparaison entre le sous-arbre de la requête et celui correspondant à chaque document dans la collection. La similarité document-requête est basée sur le calcul d’un degré d’inclusion multi-valuée traduisant jusqu’à quel point le sous-arbre de la requête est inclus dans celui du document. Différentes méthodes d’inclusion sont évaluées sur la base de leur sémantique respective. L’approche que nous proposons généralise l’approche de recherche d’information basée sur la logique floue, une évaluation sur une collection de test est également présentée.", "publication_date": "2021.09.30", "pdf_url": "https://hal.archives-ouvertes.fr/hal-03358855/file/335.pdf", "abstract_en": "The paper proposes an approach to information retrieval based on the use of a conceptual structure both for indexing document and expressing user queries. The conceptual structure is hierarchical and it is formally represented as a weighted tree. In this approach, the evaluation of queries is based on the comparison of minimal sub-trees containing the two sets of nodes corresponding to the concepts expressed in the document and the query respectively. The comparison is based on the computation of a multiple-valued degree of inclusion. Some candidate implications are discussed on the basis of their respective semantics. The proposed approach generalizes standard fuzzy information retrieval and its evaluation on benchmark example is also presented.", "lang": "fr"}
